{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "e3 procesamiento de texto y redes LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "nbTranslate": {
      "displayLangs": [
        "es",
        "en"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "es",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "48px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "358.367px"
      },
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "845e4c5403954ad7b0045f62bbc26c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c0e742336954b9c9e902c4e7eec99ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a1a85a2a2234f5eb87f095f42da8870",
              "IPY_MODEL_7171c0e4f39c4132b89c6aaec075feda"
            ]
          }
        },
        "6c0e742336954b9c9e902c4e7eec99ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a1a85a2a2234f5eb87f095f42da8870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_695aed1ea47a4a4c995b1531571d24a7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6335,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6335,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e5513f5abab43c1892b3095a03776f4"
          }
        },
        "7171c0e4f39c4132b89c6aaec075feda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a5c62b8d27140929878b76caaba52b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6335/6335 [06:29&lt;00:00, 16.27it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d2f40ffc56d43fa945fc758b2a856f6"
          }
        },
        "695aed1ea47a4a4c995b1531571d24a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e5513f5abab43c1892b3095a03776f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a5c62b8d27140929878b76caaba52b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d2f40ffc56d43fa945fc758b2a856f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D-YiltMLCEeT"
      },
      "source": [
        "# MA6202: Laboratorio de Ciencia de Datos\n",
        "\n",
        "**Profesor: NicolÃ¡s Caro**\n",
        "\n",
        "**20/07/2020 - E3 S15**\n",
        "\n",
        "\n",
        "**Integrantes del grupo**:  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zejcg_ArCEeW"
      },
      "source": [
        "## Ejercicio 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "unIMQSF-CEeZ"
      },
      "source": [
        "El objetivo de esta evaluaciÃ³n es resolver un problema de detecciÃ³n de noticias falsas (*Fake News*) usando herramientas de aprendizaje de mÃ¡quinas. \n",
        "\n",
        "Para lograr una representaciÃ³n numÃ©rica de los textos utilizaremos la librerÃ­a `spaCy` para procesamiento de lenguaje natural. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CFE7fvkSCEeb"
      },
      "source": [
        "**Instalaciones previas**  \n",
        "Para la ejecuciÃ³n correcta de este notebook puede ser necesario ejecutar los siguientes comandos de instalaciÃ³n:\n",
        "\n",
        "```python\n",
        "!pip install spacy tqdm\n",
        "!pip install -c pytorch torchtext\n",
        "!python -m spacy download en_core_web_sm\n",
        "```\n",
        "**Obs:** Puede usar conda en vez de pip si maneja su librerÃ­a con esta herramienta. \n",
        "\n",
        "Las librerÃ­as que se instalan son:\n",
        "- spacy: ampliamente usada para procesamiento de lenguaje natural. Esta librerÃ­a posee modelos estadÃ­sticos preentrenados como `en_core_web_sm` que serÃ¡ detallado posteriormente.\n",
        "- tqdm: para mostrar barras de progreso en pantalla.\n",
        "- torchtext: contiene en herramientas populares de procesamiento de lenguaje natural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2kixIAB7CEed"
      },
      "source": [
        "**LibrerÃ­as**  \n",
        "En la evaluaciÃ³n, **no** estarÃ¡ permitido usar librerÃ­as ni mÃ³dulos diferentes a los declarados en la siguiente celda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9mDw369JCEef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "44002aa1-de3f-4165-c6e5-77ecc7abfb7f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle as pk\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report,\\\n",
        "    confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "'''\n",
        "Puede utilizar esta extension si trabaja en colaboratory:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "''';\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#os.chdir(os.getcwd()+'/drive/My Drive/MA6202/E3')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbMQxVJa9-dY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0204317d-4cf8-40a9-9964-5d3186cf1399"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(os.getcwd()+'/drive/My Drive/MA6202/E3')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rA4Rg0XfCEeq"
      },
      "source": [
        "**Replicabilidad**  \n",
        "A lo largo de todo el ejercicio llamaremos mÃºltiples veces a la funciÃ³n `np.random.seed`, con la semilla fija en la variable `seed_=300`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j5gBzo2SCEes",
        "colab": {}
      },
      "source": [
        "seed_ = 300\n",
        "np.random.seed(seed_)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ML4pIcNTjIy"
      },
      "source": [
        "**Uso de GPU**  \n",
        "En este ejercicio se utilizarÃ¡n modelos que requieren alto poder de computo por lo que se recomienda usar GPU. Recuerde que en **Colaboratory** tiene acceso gratuito a dicho recurso.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OVVP3vtvUFSY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe88ba8f-1edb-43c5-c23a-e5c4ad096242"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8wc0YidsCEez"
      },
      "source": [
        "## Preliminares\n",
        "\n",
        "### Carga de datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QTqNQrWP34mq"
      },
      "source": [
        "- Compruebe que la siguiente celda coincide con este output:\n",
        "\n",
        "```\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 6335 entries, 8476 to 4330\n",
        "Data columns (total 3 columns):\n",
        " #   Column  Non-Null Count  Dtype \n",
        "---  ------  --------------  ----- \n",
        " 0   title   6335 non-null   object\n",
        " 1   text    6335 non-null   object\n",
        " 2   label   6335 non-null   object\n",
        "dtypes: object(3)\n",
        "memory usage: 198.0+ KB\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FpKqWXBvCEe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "35709bf6-2704-4a9d-ea3d-3fb14c09a742"
      },
      "source": [
        "raw_data_path = 'https://raw.githubusercontent.com/NicoCaro/DataScienceLab/master/ejercicios/ejercicio%203/data/news.csv'\n",
        "raw_df = pd.read_csv(raw_data_path, index_col=0)\n",
        "raw_df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6335 entries, 8476 to 4330\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   title   6335 non-null   object\n",
            " 1   text    6335 non-null   object\n",
            " 2   label   6335 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 198.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jHVO5t1KCEe7"
      },
      "source": [
        "**Preprocesamiento**  \n",
        "El conjunto de datos consta de 3 columnas:\n",
        "- `title`: contiene el tÃ­tulo de la noticia\n",
        "- `text`: contiene el teto de la noticia\n",
        "- `label`: contiene las etiquetas `REAL` y `FAKE` que indican si se trata de una noticia verdadera o falsa.\n",
        "\n",
        "En la siguiente celda se incluye la columna `X` con una concatenaciÃ³n del tÃ­tulo y el texto de las noticias, ademÃ¡s de la columna `y` como una representaciÃ³n numÃ©rica de la columna `label`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XrFTxJiwCEe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "edf5eac4-c6a4-4fe9-b34e-a6a21e1394a7"
      },
      "source": [
        "pro_df = raw_df.copy()\n",
        "pro_df['y'] = (pro_df['label'] == 'FAKE').astype('int')\n",
        "pro_df['X'] = pro_df['title'].str.cat(pro_df['text'], sep='. ')\n",
        "\n",
        "# se eliminan las columnas innecesarias\n",
        "pro_df = pro_df.reindex(columns=['X', 'y'])\n",
        "display(pro_df.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8476</th>\n",
              "      <td>You Can Smell Hillaryâ€™s Fear. Daniel Greenfiel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10294</th>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3608</th>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy. U...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10142</th>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       X  y\n",
              "8476   You Can Smell Hillaryâ€™s Fear. Daniel Greenfiel...  1\n",
              "10294  Watch The Exact Moment Paul Ryan Committed Pol...  1\n",
              "3608   Kerry to go to Paris in gesture of sympathy. U...  0\n",
              "10142  Bernie supporters on Twitter erupt in anger ag...  1\n",
              "875    The Battle of New York: Why This Primary Matte...  0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dX2EcoxICEfC"
      },
      "source": [
        "### Procesamiento de texto\n",
        "A modo de ejemplo se muestra el procesamiento que se busca aplicar a cada una de las observaciones de la columna `X`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-RUH-Z0KCEfE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9fbd0bc7-9991-4f10-ee9b-df539b5d682a"
      },
      "source": [
        "x_muestra, y_muestra = pro_df.iloc[3].values.T\n",
        "print('Noticia falsa' if y_muestra else 'Noticia verdadera', '-' * 72,  sep='\\n')\n",
        "print(x_muestra[:501], '...')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Noticia falsa\n",
            "------------------------------------------------------------------------\n",
            "Bernie supporters on Twitter erupt in anger against the DNC: 'We tried to warn you!'. â€” Kaydee King (@KaydeeKing) November 9, 2016 The lesson from tonight's Dem losses: Time for Democrats to start listening to the voters. Stop running the same establishment candidates. \n",
            "â€” People For Bernie (@People4Bernie) November 9, 2016 If Dems didn't want a tight race they shouldn't have worked against Bernie. \n",
            "â€” Walker Bragman (@WalkerBragman) November 9, 2016 \n",
            "New York Times columnist Paul Krugman, who was  ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jgLJ3uE1CEfJ"
      },
      "source": [
        "**DefiniciÃ³n del modelo `spacy`**  \n",
        "El modelo estadÃ­stico de `spacy` que usaremos en el ejercicio es `english_web_sm`, que consiste en un objeto basado en una red convolucional, preentrenada en un conjunto de datos llamado Ontowords y diseÃ±ada para resolver mÃºltiples tareas de procesamiento de lenguaje natural, dento de sus mÃ©todos se encuentran rutinas de tokenizaciÃ³n y lematizaciÃ³n detalladas posteriormente.\n",
        "\n",
        "Dentro de las funcionalidades que entrega este modelo, hay un subconjunto que no se utilizarÃ¡ en el ejercicio. Para ahorrar tiempo de cÃ³mputo, estas funcionalidades son deshabilitadas en el  el argumento `disable`.\n",
        "\n",
        "**Obs:** Puede ser necesario ejecutar `python -m spacy download en_core_web_sm` para tener acceso a tal modelo de lenguaje."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhOaF6SDCEfK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d78a1b68-91e2-4039-aee7-62ce0e732e4b"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['entitry_ruler', 'textcat', \n",
        "                                            'entity_linker', 'ner', 'tagger'])\n",
        "print(type(nlp))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'spacy.lang.en.English'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aUcaWEY4CEfP"
      },
      "source": [
        "**TokenizaciÃ³n**  \n",
        "\n",
        "Lo primero para analizar texto es separar el campo de texto en _tokens_. Un _token_ es un segmento significativo del texto. La entrada al tokenizer es un texto unicode, y la salida es un `spacy.tokens.doc.Doc`.\n",
        "\n",
        "\n",
        "El proceso puede entenderse como:\n",
        "1. Aplicar el mÃ©todo `str.split(' ')` que entrega una lista de `str`.\n",
        "2. Verificar si cada uno de los elementos de la lista puede subdividirse:\n",
        "    1. **Porque se trata de una regla de excepciÃ³n.** Por ejemplo `don't` deberÃ­a subdividirse en `do` y `n't`, mientras que `U.K.` no debe subdividirse.\n",
        "    2. **Porque el elemento contiene prefijos, sufijos o [infijos](https://dle.rae.es/infijo).** Por ejemplo comillas, comas, puntos, etc...\n",
        "    \n",
        "Para mÃ¡s detalles ver la documentaciÃ³n de [spacy](https://spacy.io/usage/linguistic-features#tokenization).\n",
        "\n",
        "AsÃ­ al generar *tokens* en `x_muestra`, los 20 primeros son: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JRloFA6CCEfP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a592be36-9407-466d-850f-8233cf103468"
      },
      "source": [
        "spacy_doc = nlp(x_muestra)\n",
        "[print(token) for token in spacy_doc[:20]];"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bernie\n",
            "supporters\n",
            "on\n",
            "Twitter\n",
            "erupt\n",
            "in\n",
            "anger\n",
            "against\n",
            "the\n",
            "DNC\n",
            ":\n",
            "'\n",
            "We\n",
            "tried\n",
            "to\n",
            "warn\n",
            "you\n",
            "!\n",
            "'\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oB5xDaiXCEfW"
      },
      "source": [
        "**LematizaciÃ³n**  \n",
        "La [lematizaciÃ³n](https://es.wikipedia.org/wiki/Lematizaci%C3%B3n) es el proceso de agrupar las formas flexionadas de una palabra (en plural, en femenino, conjugada, etc), para que puedan analizarse como un solo elemento, identificado por el **lema** de la palabra.\n",
        "\n",
        "En procesamiento de lenguaje natural a lematizaciÃ³n depende de la identificaciÃ³n correcta de la [categorÃ­a gramatical](https://es.wikipedia.org/wiki/Categor%C3%ADa_gramatical) (*part of speech*). Algunos ejemplos de categorÃ­a gramatical son sustantivo, adjetivo, verbo, advervio, etc...\n",
        "\n",
        "En `spacy` accedemos al lema mediante el atributo `lemma_`. AsÃ­, para los 20 primeros *tokens*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AKskjZS8CEfW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a9e23232-3e2b-408b-91a1-bb80e4c9a0aa"
      },
      "source": [
        "[print(token.lemma_) for token in spacy_doc[:20]];"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bernie\n",
            "supporter\n",
            "on\n",
            "Twitter\n",
            "erupt\n",
            "in\n",
            "anger\n",
            "against\n",
            "the\n",
            "DNC\n",
            ":\n",
            "'\n",
            "We\n",
            "try\n",
            "to\n",
            "warn\n",
            "you\n",
            "!\n",
            "'\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T0jrekzgCEfb"
      },
      "source": [
        "**Stopwords**  \n",
        "Los *tokens* generados pueden ser clasificados como [palabras vacÃ­as](https://es.wikipedia.org/wiki/Palabra_vac%C3%ADa) (*stop words*) que no tienen significado en si mismas. Algunos ejemplos son preposiciones, artÃ­culos, pronombres, etc... En procesamiento de lenguaje natural es comÃºn eliminarlas.\n",
        "\n",
        "Para este ejercicio eliminaremos las *palabras vacÃ­as* mediante el atributo `is_stop`, ademÃ¡s de los *token* que no sean alfanumÃ©ricos mediante el atributo `is_alpha`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HuBvA32OCEfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "92a47a55-7381-4d2b-bcb5-0c88bc88153a"
      },
      "source": [
        "[print(token) for token in spacy_doc[:20] if (not token.is_stop) and token.is_alpha];"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bernie\n",
            "supporters\n",
            "Twitter\n",
            "erupt\n",
            "anger\n",
            "DNC\n",
            "tried\n",
            "warn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A3x2F0cVCEfi"
      },
      "source": [
        "#### Pregunta 1\n",
        "1. Defina la funciÃ³n `procesa_texto` que reciba como argumento un texto y un modelo de lenguaje `spacy`. La funciÃ³n `procesa_texto` debe entregar un texto con los lemas de cada *token*, eliminando las palabras vacÃ­as y los *token* que no sean alfanumÃ©ricos, usando el procedimiento reciÃ©n presentado. El texto obtenido debe separar los lemas por espacios `' '`.\n",
        "2. Aplique dicha funciÃ³n a la columna `X`, guardando sus resultados en la columna `pro_X`. Como modelo de lenguaje `spacy`, utilice el modelo instanciado anteriormente.  \n",
        "    **Observaciones**:\n",
        "    - Es usual que esta operaciÃ³n tome bastante tiempo por lo que recomendamos usar el mÃ©todo `progress_apply` de pandas que permite reportar el progreso de la operaciÃ³n mediante la librerÃ­a `tqdm`. Para habilitar dicho mÃ©todo de la librerÃ­a pandas debe primero llamar al mÃ©todo `tqdm.pandas`.\n",
        "    - Puede ser Ãºtil guardar el resultado de esta operaciÃ³n en disco, dado el tiempo que toma repetir la operaciÃ³n. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EWXqJHA3CEfj",
        "colab": {}
      },
      "source": [
        "# 1\n",
        "def procesa_texto(text,spacymodel):\n",
        "  ''' Reduce un texto general a uno reducido con los lemas de cada token.\n",
        "  '''\n",
        "  spacy_doc = spacymodel(text)\n",
        "  stringlist = [token.lemma_ for token in spacy_doc if (not token.is_stop) and token.is_alpha]\n",
        "\n",
        "  return ' '.join(stringlist)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgMyTtwgbBsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "d4b6d7b9-4cbb-4e67-8c59-1d49139a104d"
      },
      "source": [
        "procesa_texto(x_muestra,nlp)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bernie supporter Twitter erupt anger DNC try warn Kaydee King November lesson tonight Dem loss Time Democrats start listen voter Stop run establishment candidate People Bernie November Dems want tight race work Bernie Walker Bragman November New York Times columnist Paul Krugman Hillary Clinton outspoken surrogate contentious Democratic primary blame Clinton poor performance Green Party candidate Jill Stein far receive negligible numb vote nationally say Stein Ralph Nader prevent Clinton victory account throw Krugman analysis face candidate issue responsibility Teachers Bernie November Ana Navarro Republican recently endorse Hillary Clinton sum preposterous nature presidential election tweet GOP nominate damn candidate lose Hillary Clinton Democrats nominate damn candidate lose Trump Ana Navarro November Popular leave wing Facebook page pro Sanders primary respond Trump surge simply post meme Sanders face text avoid Thanks DNC meme share time hour Posted Tuesday November Bernie Sanders endorse Hillary Clinton Democratic National Convention July supporter remain adamant refusal support DNC anoint candidate point WikiLeaks revelation official DNC work scene tip scale Clinton favor coordinate medium figure circulate anti Sanders narrative attribute potential Trump presidency GOP nominee perceive popularity voter closeness election credit Hillary Clinton unfavorable rating According RealClearPolitics percent voter negative opinion Democratic nominee PM Eastern Florida Michigan Pennsylvania Wisconsin remain close Clinton electoral vote Trump Zach Cartwright activist author Richmond Virginia enjoy write politic government medium Send email email protect'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkoPKcs1dSYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2\n",
        "tqdm.pandas()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyoFEevZcZqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "845e4c5403954ad7b0045f62bbc26c59",
            "6c0e742336954b9c9e902c4e7eec99ba",
            "9a1a85a2a2234f5eb87f095f42da8870",
            "7171c0e4f39c4132b89c6aaec075feda",
            "695aed1ea47a4a4c995b1531571d24a7",
            "4e5513f5abab43c1892b3095a03776f4",
            "4a5c62b8d27140929878b76caaba52b2",
            "0d2f40ffc56d43fa945fc758b2a856f6"
          ]
        },
        "outputId": "34bbb41c-2d4d-4451-a768-a6b32658dde7"
      },
      "source": [
        "# Se genera la columna de textos procesados 'pro_X'\n",
        "pro_df['pro_X'] = pro_df.loc[:,'X'].progress_apply(lambda x : procesa_texto(x,nlp))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "845e4c5403954ad7b0045f62bbc26c59",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6335.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEgK0fcp3QSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "17510266-8ed4-41ec-d1c8-e7a60f6b0fff"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/MA6202/E3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQzzySO5f7Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se guarda el df generado en un archivo .pkl\n",
        "pro_df.to_pickle(os.getcwd()+'/data/pro_df.pkl')\n",
        "\n",
        "# Se carga el df del archivo .pkl previamente guardado\n",
        "pro_df = pd.read_pickle(os.getcwd() + '/data/pro_df.pkl')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNj4NWFKg73V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "59e146ed-8c0d-4783-edba-76ead959062a"
      },
      "source": [
        "pro_df"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>y</th>\n",
              "      <th>pro_X</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8476</th>\n",
              "      <td>You Can Smell Hillaryâ€™s Fear. Daniel Greenfiel...</td>\n",
              "      <td>1</td>\n",
              "      <td>Smell Hillary Fear Daniel Greenfield Shillman ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10294</th>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>1</td>\n",
              "      <td>Watch Exact Moment Paul Ryan Committed Politic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3608</th>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy. U...</td>\n",
              "      <td>0</td>\n",
              "      <td>Kerry Paris gesture sympathy Secretary State J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10142</th>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>1</td>\n",
              "      <td>Bernie supporter Twitter erupt anger DNC try w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
              "      <td>0</td>\n",
              "      <td>Battle New York Primary Matters primary day Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4490</th>\n",
              "      <td>State Department says it can't find emails fro...</td>\n",
              "      <td>0</td>\n",
              "      <td>State Department say find email Clinton specia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8062</th>\n",
              "      <td>The â€˜Pâ€™ in PBS Should Stand for â€˜Plutocraticâ€™ ...</td>\n",
              "      <td>1</td>\n",
              "      <td>P PBS Stand Plutocratic Pentagon P PBS Stand P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8622</th>\n",
              "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
              "      <td>1</td>\n",
              "      <td>Anti Trump Protesters Tools Oligarchy Informat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4021</th>\n",
              "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
              "      <td>0</td>\n",
              "      <td>Ethiopia Obama seek progress peace security Ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4330</th>\n",
              "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
              "      <td>0</td>\n",
              "      <td>Jeb Bush Suddenly Attacking Trump Matters Jeb ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6335 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       X  ...                                              pro_X\n",
              "8476   You Can Smell Hillaryâ€™s Fear. Daniel Greenfiel...  ...  Smell Hillary Fear Daniel Greenfield Shillman ...\n",
              "10294  Watch The Exact Moment Paul Ryan Committed Pol...  ...  Watch Exact Moment Paul Ryan Committed Politic...\n",
              "3608   Kerry to go to Paris in gesture of sympathy. U...  ...  Kerry Paris gesture sympathy Secretary State J...\n",
              "10142  Bernie supporters on Twitter erupt in anger ag...  ...  Bernie supporter Twitter erupt anger DNC try w...\n",
              "875    The Battle of New York: Why This Primary Matte...  ...  Battle New York Primary Matters primary day Ne...\n",
              "...                                                  ...  ...                                                ...\n",
              "4490   State Department says it can't find emails fro...  ...  State Department say find email Clinton specia...\n",
              "8062   The â€˜Pâ€™ in PBS Should Stand for â€˜Plutocraticâ€™ ...  ...  P PBS Stand Plutocratic Pentagon P PBS Stand P...\n",
              "8622   Anti-Trump Protesters Are Tools of the Oligarc...  ...  Anti Trump Protesters Tools Oligarchy Informat...\n",
              "4021   In Ethiopia, Obama seeks progress on peace, se...  ...  Ethiopia Obama seek progress peace security Ea...\n",
              "4330   Jeb Bush Is Suddenly Attacking Trump. Here's W...  ...  Jeb Bush Suddenly Attacking Trump Matters Jeb ...\n",
              "\n",
              "[6335 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m_QePI5bCEfq"
      },
      "source": [
        "3. Cuente el nÃºmero de lemas en cada observaciÃ³n de la columna `pro_X` y compruebe que obtiene las siguientes estadÃ­sticas descriptivas:\n",
        "\n",
        "```\n",
        "count    6335.000000\n",
        "mean      393.084294\n",
        "std       409.950812\n",
        "min         2.000000\n",
        "25%       153.000000\n",
        "50%       311.000000\n",
        "75%       515.000000\n",
        "max      8730.000000\n",
        "Name: pro_X, dtype: float64\n",
        "```\n",
        "*Hint*: puede ser Ãºtil el mÃ©todo `pd.Series.str.count`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MWGdXsbPD4ow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b6c93460-7791-4a52-8a6e-ef3996a02613"
      },
      "source": [
        "# 3\n",
        "pro_df.loc[:,'pro_X'].str.count(pat=' ').describe()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    6335.000000\n",
              "mean      392.084294\n",
              "std       409.950812\n",
              "min         1.000000\n",
              "25%       152.000000\n",
              "50%       310.000000\n",
              "75%       514.000000\n",
              "max      8729.000000\n",
              "Name: pro_X, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U_nsPKTtCEfv"
      },
      "source": [
        "4. Instancie `final_df` como una copia de `pro_df` a la que se le elimina la columna `'X'`. Luego aplique la eliminaciÃ³n de los duplicados `final_df`.   \n",
        "- Compruebe que obtiene un total de 6,303 filas Ãºnicas en `final_df`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_88ZW5V4D-7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "329dde92-99f1-4edf-bd78-71923ebb4934"
      },
      "source": [
        "# 4\n",
        "final_df = pro_df.reindex(columns=['pro_X', 'y'], copy=True).drop_duplicates()\n",
        "final_df"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pro_X</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8476</th>\n",
              "      <td>Smell Hillary Fear Daniel Greenfield Shillman ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10294</th>\n",
              "      <td>Watch Exact Moment Paul Ryan Committed Politic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3608</th>\n",
              "      <td>Kerry Paris gesture sympathy Secretary State J...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10142</th>\n",
              "      <td>Bernie supporter Twitter erupt anger DNC try w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>Battle New York Primary Matters primary day Ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4490</th>\n",
              "      <td>State Department say find email Clinton specia...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8062</th>\n",
              "      <td>P PBS Stand Plutocratic Pentagon P PBS Stand P...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8622</th>\n",
              "      <td>Anti Trump Protesters Tools Oligarchy Informat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4021</th>\n",
              "      <td>Ethiopia Obama seek progress peace security Ea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4330</th>\n",
              "      <td>Jeb Bush Suddenly Attacking Trump Matters Jeb ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6303 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   pro_X  y\n",
              "8476   Smell Hillary Fear Daniel Greenfield Shillman ...  1\n",
              "10294  Watch Exact Moment Paul Ryan Committed Politic...  1\n",
              "3608   Kerry Paris gesture sympathy Secretary State J...  0\n",
              "10142  Bernie supporter Twitter erupt anger DNC try w...  1\n",
              "875    Battle New York Primary Matters primary day Ne...  0\n",
              "...                                                  ... ..\n",
              "4490   State Department say find email Clinton specia...  0\n",
              "8062   P PBS Stand Plutocratic Pentagon P PBS Stand P...  1\n",
              "8622   Anti Trump Protesters Tools Oligarchy Informat...  1\n",
              "4021   Ethiopia Obama seek progress peace security Ea...  0\n",
              "4330   Jeb Bush Suddenly Attacking Trump Matters Jeb ...  0\n",
              "\n",
              "[6303 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pbojUolFCEf2"
      },
      "source": [
        "### DefiniciÃ³n de notaciÃ³n\n",
        "De ahora en adelante denotamos por:\n",
        "- ***Documento***: cada una de las noticias procesadas del conjunto de datos, es decir, cada una de las observaciones de la columna `'pro_X'`del DataFrame `final_df`.\n",
        "- ***Corpus***: el conjunto de *documentos* del conjunto de datos, es decir, el conjunto de observaciones de la columna `'pro_X'` del DataFrame `final_df`.\n",
        "- ***Vocabulario***: al conjunto de *tokens* presentes en el *corpus*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ySZAaNLlCEf3"
      },
      "source": [
        "### DefiniciÃ³n de conjuntos del problema\n",
        "Se separan las muestras en dos conjuntos:\n",
        "- Conjunto de *entrenamiento union validaciÃ³n* (denotado por `*_full_train`), con el 80% de las observaciones\n",
        "- Conjunto de *prueba* (denotado por `*_test`), con el 20% de las observaciones.\n",
        "\n",
        "A su vez el conjunto de *entrenamiento union validaciÃ³n* de subdivide en:\n",
        "- Conjunto de *entrenamiento* (denotado por `*_train`), con el 64% de las observaciones.\n",
        "- Conjunto de *validaciÃ³n* (denotado por `*_val`), con el 16% de las observaciones\n",
        "\n",
        "Para realizar esta subdivisiÃ³n utilizamos dos veces la funciÃ³n `sklearn.model_selection.train_test_split`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2YYSQ9p4CEf7",
        "colab": {}
      },
      "source": [
        "# define parametros de la division de conjuntos\n",
        "proporcion_total_entrenamiento_prueba = 0.80\n",
        "proporcion_entrenamiento_validacion = 0.80\n",
        "\n",
        "# obtiene conjunto de prueba\n",
        "X_full_train, X_test, y_full_train, y_test= train_test_split(\n",
        "    final_df.pro_X, final_df.y, train_size=proporcion_total_entrenamiento_prueba, \n",
        "    random_state=seed_)\n",
        "\n",
        "# obtiene conjunto de entrnamiento y validacion\n",
        "X_train, X_val, y_train, y_val  = train_test_split(\n",
        "    X_full_train, y_full_train, train_size=proporcion_entrenamiento_validacion, \n",
        "    random_state=seed_)\n",
        "\n",
        "# guardar los conjuntos en formato csv\n",
        "conjuntos_dir = 'conjuntos'\n",
        "os.makedirs(conjuntos_dir, exist_ok=True)\n",
        "guarda_csv = lambda X, y, filename: pd.DataFrame({\n",
        "    'pro_X': X, 'y': y\n",
        "}).to_csv(f'{conjuntos_dir}/{filename}.csv', index=None)\n",
        "guarda_csv(X_train, y_train, 'entrenamiento')\n",
        "guarda_csv(X_val, y_val, 'validacion')\n",
        "guarda_csv(X_test, y_test, 'prueba')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yDRxP4ebCEf_"
      },
      "source": [
        "## Modelos de aprendizaje de mÃ¡quinas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pAg8An6BEsDg"
      },
      "source": [
        "### Modelos no paramÃ©tricos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2kljsRVFCEgA"
      },
      "source": [
        "#### RepresentaciÃ³n por conteo de ocurrencias.\n",
        "Dado que se busca resolver un problema de clasificaciÃ³n de documentos, es necesario representar los documentos de forma numÃ©rica. A continuaciÃ³n usaremos la representaciÃ³n por conteo de apariciones de cada uno de los *tokens* presentes en el *vocabulario*.\n",
        "\n",
        "Para realizar esta vectorizaciÃ³n de documentos se utiliza la clase `sklearn.feature_extraction.text.CountVectorizer`. El mÃ©todo `fit_transform` de esta clase  recibe como argumento un `iterable` de *documentos*, extrae el *vocabulario* de dicho `iterable` y retorna la matriz de nÃºmero de ocurrencias de cada *token* del *vocabulario*, en cada uno de los documentos del `iterable`. En otras palabras, definiendo $\\text{tf}(t_i, \\mathbf{d}_j)$ como el nÃºmero de apariciones del *token* $t_i$ en el *documento* $\\mathbf{d}_j$, `~CountVectorizer.fit_transform` retorna la matriz $\\mathbf{C}$ definida por:\n",
        "$$\\big(c_{i, j}\\big) = \\text{tf}(t_j, \\mathbf{d}_i)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "14YOBySYCEgB"
      },
      "source": [
        "#### Naive Bayes\n",
        "\n",
        "Se emplea el algoritmo de *Naive Bayes* como base de referencia para los modelos mÃ¡s complejos empleados posteriormente. EspecÃ­ficamente, se utiliza una instancia de la clase `sklearn.naive_bayes.MultinomialNB` que estÃ¡ diseÃ±ado para trabajar con las caracterÃ­sticas del tipo conteo. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LXS7kANE0A-"
      },
      "source": [
        "##### Pregunta 2\n",
        "1. Instancie `nb_pipe` como un objeto de la clase `sklearn.pipeline.Pipeline` con los componentes:\n",
        "    - `~CountVectorizer` inicializado con `max_features=20000` los demÃ¡s parÃ¡metros por defecto.\n",
        "    - `~MultinomialNB` inicializado con los parÃ¡metros por defecto.  \n",
        "    \n",
        "   Posteriormente, ajuste `nb_pipe` en el conjunto de *entrenamiento union validaciÃ³n* y guarde el modelo resultante en la carpeta `modelos/nb_pipe.pk` como un archivo `pickle`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KBiY5mcwEC1N",
        "colab": {}
      },
      "source": [
        "# 1\n",
        "# Se crea la pipeline\n",
        "nb_pipe = Pipeline(steps=[('vectorizacion',CountVectorizer(max_features=20000)),\n",
        "                          ('naive_bayes', MultinomialNB())] \n",
        "                   )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuuyYxSaxpAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1352e12b-d3a7-4933-8614-7c6b07609258"
      },
      "source": [
        "# Se realiza el ajuste sobre entrenamiento 'union' validaciÃ³n, \n",
        "# es decir, en X_full_train, y_full_train\n",
        "nb_pipe.fit(X_full_train,y_full_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizacion',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=20000, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('naive_bayes',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kts6-fzrLcYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se guarda el modelo en un archivo .pk\n",
        "os.makedirs(os.getcwd() + f'/modelos/', exist_ok=True)\n",
        "\n",
        "with open(os.getcwd() + '/modelos/nb_pipe.pk', 'wb') as handler:\n",
        "  pk.dump(nb_pipe, handler)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8R4IVhILCEgG"
      },
      "source": [
        "2. Defina la funciÃ³n `evalua_sklearn`  que reciba como argumentos:\n",
        "    - `y_true`: np.array de una dimensiÃ³n, conteniendo las etiquetas de cada una de las observaciones \n",
        "    - `y_pred`: np.array, con las etiquetas predichas por algÃºn modelo de clasificaciÃ³n\n",
        "    - `nombre_clasificador`: str, define el nombre de la carpeta donde los resultados son guardados. \n",
        "    \n",
        "  Esta funciÃ³n debe:\n",
        "    - Imprimir en pantalla los resultados de clasificaciÃ³n, mediante `sklearn.metrics.classification_report` con 4 dÃ­gitos de precisiÃ³n. AdemÃ¡s debe guardar dichos resultadoes  en la ruta `f'resultados/{nombre_clasificador}/reporte_clasificacion.txt'`.\n",
        "    - Generar un grÃ¡fico con la *matriz de confusiÃ³n* mediante el uso de `sklearn.metrics.confusion_matrix` y `seaborn.heatmap`. AdemÃ¡s debe guardar dicho grÃ¡fico en la ruta `f'resultados/{nombre_clasificador}/mc.pdf'`.\n",
        "    \n",
        "  Pruebe esta funciÃ³n con la predicciÃ³n de `nb_pipe` sobre el conjunto de *prueba*, usando `nombre_clasificador='nb_pipe'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86egea5I2zV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2\n",
        "def evalua_sklearn(y_true,y_pred,nombre_clasificador):\n",
        "\n",
        "  # Se crea el directorio con resultados en caso de no existir\n",
        "  os.makedirs(os.getcwd() + f'/resultados/{nombre_clasificador}', exist_ok=True)\n",
        "  \n",
        "  # Imprime en pantalla los resultados de la clasificaciÃ³n \n",
        "  print(classification_report(y_true,y_pred,digits=4))\n",
        "\n",
        "  # Se crea un archivo y se guardan los resultados\n",
        "  with open(os.getcwd() + f'/resultados/{nombre_clasificador}/reporte_clasificacion.txt', 'w+') as f:\n",
        "    print(classification_report(y_true,y_pred,digits=4), file=f)\n",
        "  \n",
        "  # Se crea y guarda el grÃ¡fico con la matrÃ­z de confusiÃ³n \n",
        "  sns.heatmap(confusion_matrix(y_true=y_true, y_pred=y_pred))\n",
        "  plt.savefig(f'resultados/{nombre_clasificador}/mc.pdf', \n",
        "              format='pdf', bbox_inches='tight')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "opHsYtdSEH6J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "5abe4a78-54c5-42ac-9573-71d8ba928000"
      },
      "source": [
        "# Se evalua el desempeÃ±o del modelo en el conjunto de prueba\n",
        "y_test_pred_nb = nb_pipe.predict(X_test)\n",
        "evalua_sklearn(y_test, y_test_pred_nb,'nb_pipe')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8895    0.9217    0.9053       664\n",
            "           1     0.9092    0.8727    0.8906       597\n",
            "\n",
            "    accuracy                         0.8985      1261\n",
            "   macro avg     0.8994    0.8972    0.8980      1261\n",
            "weighted avg     0.8989    0.8985    0.8984      1261\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dQ1wjJUqCEgM"
      },
      "source": [
        "- Compruebe que obtiene un *accuracy* y un promedio ponderado de *f1-score* superiores a .89.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4S1h1zjAHkC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9a338add-951e-42ba-ac9a-4448a50451f3"
      },
      "source": [
        "f1_scores = np.array([0.9053,0.8906, 0.8985, 0.8980, 0.8984]) # aÃºn no se como extraer del .txt\n",
        "print('accuracy_score:', accuracy_score(y_true=y_test,y_pred=y_test_pred_nb))\n",
        "print('mean f1_score:', np.mean(f1_scores))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score: 0.8984932593180016\n",
            "mean f1_score: 0.8981600000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F29MRA-xCEgN"
      },
      "source": [
        "#### RepresentaciÃ³n Tf-idf\n",
        "\n",
        "Para esta secciÃ³n y la posterior se emplea la clase `sklearn.feature_extraction.text.TfidfVectorizer`. \n",
        "\n",
        "Para comprender el algoritmo ***tf-idf*** (*term frequency - inverse document frequency*) necesitamos definir 3 de sus componentes:\n",
        "- $\\text{tf}(t_j, \\mathbf{d}_i)$ que representa el nÃºmero de apariciones del *token* $t_j$ en el *documento* $\\mathbf{d}_i$.\n",
        "\n",
        "- $\\text{df}(t_j)$ que representa el nÃºmero de documentos en que aparece el *token* $t_j$.\n",
        "- $\\text{idf}(t_j)$ que representa el inverso de la frecuencia del *token* $t_j$ en los *documentos* del *corpus*. En el caso particular del objeto `~.TfidfVectorizer` empleado, denotando por $n$ al numero de documentos del *corpus*, se usa una versiÃ³n suavizada de la funciÃ³n $\\text{idf}$. Esto es: \n",
        "\n",
        "$$\n",
        "\\text{idf}(t_j) = \\log(\\frac{1 + n}{1 + \\text{df}(t_j)}) + 1\n",
        "$$\n",
        "\n",
        "\n",
        "Con dichos componentes, podemos definir a la representaciÃ³n vectorial del documento $\\mathbf{d}_i$ mediante el vector $\\textbf{tf-idf}(\\mathbf{d}_i)$, cuyas coordenadas se calculan de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\\left(\\textbf{tf-idf}(\\mathbf{d}_i)_i\\right) = \\text{tf}(t_j, \\mathbf{d}_i) \\times \\text{idf}(t_j)\n",
        "$$\n",
        "\n",
        "\n",
        "AsÃ­ la salida del objeto `~.TfidfVectorizer` es la matriz de la concatenaciÃ³n por filas, de los vectores $\\textbf{tf-idf}(\\mathbf{d}_i)$ normalizados segÃºn la norma euclidiana, es decir, la matriz $\\mathbf{X}$, definida por:\n",
        "\n",
        "\n",
        "$$\n",
        "\\left( x_{i,j} \\right) = \\frac{\\text{tf}(t_j, \\mathbf{d}_i) \\times \\text{idf}(t_j)}{{||\\textbf{tf-idf}(\\mathbf{d}_i)||}_2} \n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "donde ${||\\cdot||}_2$ representa la norma euclidiana. En consecuencia se logra una representaciÃ³n vectorial sobre la esfera unitaria de la norma ${||\\cdot||}_2$.\n",
        "\n",
        "Una interpretaciÃ³n posible de esta representaciÃ³n vectorial es que cada *token* $t_j$ tiene mayor importancia en el documento $\\mathbf{d}_i$:\n",
        "\n",
        "- En la medida en que esta aparezca mÃ¡s veces en el documento\n",
        "- En la medida en que esta aparezca menos veces en los demÃ¡s documentos del corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M8A8IZPoCEgN"
      },
      "source": [
        "#### Maquinas de soporte vectorial (SVM)\n",
        "\n",
        "Se emplea el algoritmo de mÃ¡quinas de soporte vectorial (*Support Vector Machines - SVM*) sobre la representaciÃ³n vectorial *tf-idf*. La clase utilizada para generar este modelo es `sklearn.svm.SVC`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1_rQh6ZPE4dA"
      },
      "source": [
        "##### Pregunta 3\n",
        "1. Instancie `svm_pipe` como un objeto de la clase `sklearn.pipeline.Pipeline` con los componentes:\n",
        "    - `~.TfidfVectorizer` inicializado con `max_features=20000` los demÃ¡s parÃ¡metros por defecto.\n",
        "    - `~.SVC` inicializado con el kernel RBF y los parÃ¡metros por defecto.  \n",
        "    \n",
        "   Posteriormente, ajuste `svm_pipe` en el conjunto de *entrenamiento union validaciÃ³n* y guarde el modelo resultante en la carpeta `modelos/svm_pipe.pk` como un archivo `pickle`. Finalmente, reporte el desempeÃ±o del clasificador mediante `evalua_sklearn` con la predicciÃ³n de `svm_pipe` sobre el conjunto de *prueba*, usando `nombre_clasificador='svm_pipe'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C-fRguPeELN-",
        "colab": {}
      },
      "source": [
        "# 1\n",
        "# Se crea la pipeline\n",
        "svm_pipe = Pipeline(steps=[('vector Tfidf', TfidfVectorizer(max_features=20000)),\n",
        "                           ('svc', SVC())]\n",
        "                    )"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhorb87sPiAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se ajusta el modelo al conjunto de entrenamiento union validaciÃ³n, i.e.,\n",
        "# a X_full_train e y_full_train\n",
        "svm_pipe.fit(X_full_train,y_full_train)\n",
        "\n",
        "# Se guarda el modelo en un archivo .pk\n",
        "os.makedirs(os.getcwd() + f'/modelos/', exist_ok=True)\n",
        "\n",
        "with open(os.getcwd() + '/modelos/svm_pipe.pk', 'wb') as handler:\n",
        "  pk.dump(svm_pipe, handler)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCBdnG1FPoQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "4af25ab6-b198-47f6-b5a0-01d16966457f"
      },
      "source": [
        "# Se evalua el desempeÃ±o del modelo en el conjunto de test\n",
        "y_test_pred_svm = svm_pipe.predict(X_test)\n",
        "evalua_sklearn(y_test, y_test_pred_svm,'svm_pipe')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9507    0.9006    0.9250       664\n",
            "           1     0.8956    0.9481    0.9211       597\n",
            "\n",
            "    accuracy                         0.9231      1261\n",
            "   macro avg     0.9231    0.9243    0.9230      1261\n",
            "weighted avg     0.9246    0.9231    0.9231      1261\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xj3HbM47CEgT"
      },
      "source": [
        "Las mÃ¡quinas de soporte vectorial son algoritmos que pueden ser muy sensibles a los hiperparÃ¡metros. Por esta razÃ³n es Ãºtil emplear un esquema de validaciÃ³n cruzada. A continuaciÃ³n se implementa un esquema de validaciÃ³n cruzada simple, que explora sÃ³lo diferentes kernels y coeficientes de regularizaciÃ³n.\n",
        "2. Instancie `svm_grid` como un objeto de la clase `sklearn.model_selection.GridSearchCV`con los parÃ¡metros:\n",
        "    - `n_jobs=-1` para usar todos los nÃºcleos disponibles\n",
        "    - `param_grid` definido de tal forma que le permita probar las combinaciones de los siguientes hiperparÃ¡metros de `~SVC`:\n",
        "        - `kernel` en {`'lineal'`, `'rbf'`}\n",
        "        - `C` en {`.01`, `.1`, `1`, `10`, `100`}\n",
        "\n",
        "    - `cv=3` para generar un esquema de validaciÃ³n cruzada estratificada con 3 *fold*.\n",
        "    - `verbose=1` para reportar el progreso del ajuste en pantalla\n",
        "    \n",
        "  Los demÃ¡s parÃ¡metros quedan con sus valores por defecto.  \n",
        "  \n",
        "  Ajuste `grid_search_svm` usando `svm_pipe` sobre el conjunto *entrenamiento union validaciÃ³n* y guarde el modelo resultante en la carpeta `modelos/svm_grid.pk` como un archivo `pickle`. Luego reporte el desempeÃ±o del clasificador mediante `evalua_sklearn` con la predicciÃ³n de `svm_grid` sobre el conjunto de *prueba*, usando `nombre_clasificador='svm_grid'`.  \n",
        "  \n",
        "  **Obs**: Evite fuga de informaciÃ³n al combinar ``svm_pipe`` con `grid_search_svm`.\n",
        "\n",
        "  Finalmente, en ruta `resultados/svm_grid/mejores_parametros.txt` guarde los mejores parÃ¡metros obtenidos en `svm_grid`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TJJyKChuEOLr",
        "colab": {}
      },
      "source": [
        "# no olvide fijar la semilla \n",
        "np.random.seed(seed_)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4W_WeEpXPUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se genera la grilla de parÃ¡metros\n",
        "grid = [{'svc__kernel': ['lineal'],\n",
        "         'svc__C': [0.01, 0.1, 1, 10, 100]},\n",
        "        {'svc__kernel': ['rbf'],\n",
        "         'svc__C': [0.01, 0.1, 1, 10, 100]}\n",
        "        ]\n",
        "\n",
        "# Se comienza el modelo de bÃºsqueda\n",
        "svm_grid = GridSearchCV(estimator=svm_pipe, param_grid=grid, n_jobs=-1, cv=3, verbose=1) "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB9CAAEEYA7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "10a16241-d5b6-4b87-c861-7522444d5f0b"
      },
      "source": [
        "# Se ajusta el modelo al conjunto de entrenamiento union validaciÃ³n, i.e.,\n",
        "# a X_full_train e y_full_train\n",
        "svm_grid.fit(X_full_train, y_full_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  5.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vector Tfidf',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=20000,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words=None,\n",
              "                                                        st...\n",
              "                                            kernel='rbf', max_iter=-1,\n",
              "                                            probability=False,\n",
              "                                            random_state=None, shrinking=True,\n",
              "                                            tol=0.001, verbose=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid=[{'svc__C': [0.01, 0.1, 1, 10, 100],\n",
              "                          'svc__kernel': ['lineal']},\n",
              "                         {'svc__C': [0.01, 0.1, 1, 10, 100],\n",
              "                          'svc__kernel': ['rbf']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxkyMeCBauuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se guarda el modelo en un archivo .pk\n",
        "os.makedirs(os.getcwd() + f'/modelos/', exist_ok=True)\n",
        "\n",
        "with open(os.getcwd() + '/modelos/svm_grid.pk', 'wb') as handler:\n",
        "  pk.dump(svm_grid, handler)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBJFSGnudh4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "446cd152-ff5b-46c9-de27-b18257ba6768"
      },
      "source": [
        "# Se evalua el desempeÃ±o del modelo en el conjunto de test\n",
        "y_test_pred_svm_grid = svm_grid.predict(X_test)\n",
        "evalua_sklearn(y_test, y_test_pred_svm_grid,'svm_grid')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9528    0.9111    0.9315       664\n",
            "           1     0.9058    0.9497    0.9272       597\n",
            "\n",
            "    accuracy                         0.9294      1261\n",
            "   macro avg     0.9293    0.9304    0.9294      1261\n",
            "weighted avg     0.9305    0.9294    0.9295      1261\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeKLK9sWeOsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se recupera el mejor modelo obtenido de la bÃºsqueda\n",
        "svm_grid_best = svm_grid.best_estimator_\n",
        "\n",
        "# Se guardan los mejores parametros en un archivo .txt\n",
        "with open(os.getcwd() + f'/resultados/svm_grid/mejores_parametros.txt', 'w+') as f:\n",
        "  print(svm_grid_best.get_params(),file=f)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CW8MfC6GEdgD"
      },
      "source": [
        "### Modelos paramÃ©tricos\n",
        "\n",
        "En lo que sigue del ejercicio se construirÃ¡ una red neuronal recurrente (*RNN*). Para ello se usarÃ¡ principalmente la librerÃ­a `torchtext` que provee una serie de herramientas que facilitan el manejo de texto para redes neuronales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pqXRozFCFCYS"
      },
      "source": [
        "#### RepresentaciÃ³n vectorial densa\n",
        "\n",
        "En las representaciones vectoriales anteriores, cada *token* del *vocabulario* constituye una dimension del espacio, es decir, hay tantas dimensiones en el espacio vectorial de representaciÃ³n como *tokens* en el *vocabulario*.\n",
        "\n",
        "Hay una desventaja enorme en esta representaciÃ³n, ademÃ¡s de la cantidad enorme de dimensiones que genera. Esta es que bÃ¡sicamente trata todos los *token* como entidades independientes sin relaciÃ³n entre sÃ­. Lo que se busca en una representaciÃ³n densa es alguna nociÃ³n de similitud entre las palabras.\n",
        "\n",
        "Por ejemplo, supoga que se construye un modelo de lenguaje y que hemos visto las oraciones:\n",
        "\n",
        "- El matemÃ¡tico corriÃ³ a la tienda.\n",
        "- El fÃ­sico corriÃ³ a la tienda.\n",
        "- El matemÃ¡tico resolviÃ³ un problema abierto.\n",
        "\n",
        "en el conjunto de *entrenamiento*. Ahora supongamos que obtenemos una nueva oraciÃ³n no presente en el conjunto de *entrenamiento*:\n",
        "\n",
        "- El fÃ­sico resolviÃ³ un problema abierto.\n",
        "\n",
        "Si bien el modelo de lenguaje puede funcionar bien en esta oraciÃ³n, serÃ­a mejor si se pudiera utilizar los siguientes aspectos:\n",
        "\n",
        "- Se ha observado matemÃ¡tico y fÃ­sico en el mismo papel en una oraciÃ³n. De alguna manera tienen una relaciÃ³n semÃ¡ntica.\n",
        "- Se ha observado al matemÃ¡tico en el rol del fÃ­sico en una oraciÃ³n anÃ¡loga a esta nueva oraciÃ³n.\n",
        "\n",
        "AsÃ­, se podrÃ­a inferir que el fÃ­sico en realidad encaja bien en la nueva oraciÃ³n. Esto esconde una nociÃ³n de similitud: queremos decir similitud semÃ¡ntica, no simplemente tener representaciones ortogrÃ¡ficas similares. Este ejemplo, por supuesto, se basa en una suposiciÃ³n lingÃ¼Ã­stica fundamental: que las palabras que aparecen en contextos similares estÃ¡n relacionadas semÃ¡nticamente entre sÃ­. Esto se llama hipÃ³tesis ***distribucional***.\n",
        "\n",
        "Sobre dicha hipotesis se basa la construcciÃ³n de modelos de procesamiento de lenguaje natural llamado ***word embeddings*** que se utilizan a continuaciÃ³n.\n",
        "\n",
        "<center>ExplicaciÃ³n adaptada de <a href=\"https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\">Word Embedding: Encoding Lexical Semantics - Pytorch</a></center> \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wRUh3opLLJ3P"
      },
      "source": [
        "##### Pregunta 4 \n",
        "La forma de cargar datos en formato csv que provee `torchtext`, es mediante los objetos `torchtext.data.dataset.TabularDataset`. A direfencia de `pandas.read_csv`, donde la funciÃ³n puede inferir el tipo de dato de cada columna, `~.TabularDataset` necesita que dichos tipos de dato sean declarados, mediante el objeto `torchtext.data.Field`.\n",
        "\n",
        "1. Instancie `train_td`, `val_td` y `test_td` mediante el mÃ©todo `~.TabularDataset.splits` que le permita cargar textos de los archivos `conjuntos/*.csv` respectivos. Para ello tendrÃ¡ que instanciar dos objetos de la clase `~.Field` que definan el tipo de dato para cada columna:\n",
        "\n",
        "- La columna `y`: declarada mediante el objeto `etiqueta_fd` como instancia de `~.Field`, con parametros `sequential=False, use_vocab=False, batch_first=True, dtype=torch.float` y los demÃ¡s por defecto.\n",
        "- La columna `pro_X`:  declarada mediante el objeto `documento_fd`, como instancia de `~.Field`, con parÃ¡metros `include_lengths=True, batch_first=True` y los demÃ¡s por defecto. El primer parÃ¡metro (`include_lengths=True`) implica que cada *documento* cargado de la columna se entregarÃ¡ en forma de tupla, donde ademÃ¡s de la secuencia de *tokens* de aquel *documento*, se adjuntarÃ¡ el largo de la secuencia o nÃºmero de tokens contenidos en este.\n",
        "\n",
        "**Obs**: TendrÃ¡ que inferir los parÃ¡metros con los cuales emplear el mÃ©todo `~.splits()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_CPFslHMO7OF",
        "colab": {}
      },
      "source": [
        "etiqueta_fd=Field(sequential=False,use_vocab=False,batch_first=True,dtype=torch.float)\n",
        "documento_fd=Field(include_lengths=True,batch_first=True)\n",
        "\n",
        "\n",
        "train_td, val_td, test_td = TabularDataset.splits(\n",
        "    path=os.getcwd() + '/conjuntos/', train='entrenamiento.csv',\n",
        "    validation='validacion.csv', test='prueba.csv', format='csv',\n",
        "    fields=[('documento', documento_fd), ('etiqueta', etiqueta_fd)])\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2ZQsjBrESIYZ"
      },
      "source": [
        "`torchtext` tambiÃ©n provee objetos que permiten iterar sobre un objeto de tipo `~.TabularDataset`. En particular, en el procesamiento de texto es beneficioso generar *batches* de secuencias que tengan largo similar, para ahorrar tiempo de escritura, ya que dichos *batches* al tener forma tensorial, deben ser completados por ceros (*padding*). AsÃ­ por ejemplo, las secuencias:\n",
        "```\n",
        "[ [4, 16, 3, 8],\n",
        "  [5, 2],\n",
        "  [6, 6, 7, 9, 2] ]\n",
        "```\n",
        "deben ser transformadas a:\n",
        "```\n",
        "[ [4, 16, 3, 8, 0],\n",
        "  [5, 2, 0, 0, 0],\n",
        "  [6, 6, 7, 8, 2] ]\n",
        "```\n",
        "\n",
        "Mediante la clase ` torchtext.data.BucketIterator`, es posible iterar sobre instancias de `~.TabularDataset`, de manera que se minimiza la cantidad de *padding* y al mismo tiempo se mantiene un orden aleatorio de los datos.\n",
        "\n",
        "2.  Instancie *iterators* de cada uno de los `~.TabularDataset` instanciados, mediante `~.BucketIterator.splits` con los parÃ¡metros `batch_size=32, sort_key=lambda x: len(x.pro_X),\n",
        "device=device, sort=True, sort_within_batch=True`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zvPAvN1eUX9E",
        "colab": {}
      },
      "source": [
        "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
        "    (train_td, val_td, test_td), batch_sizes=(32, 32, 32),\n",
        "    sort_key=lambda x: len(x.pro_X), device=device,sort=True, sort_within_batch=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PI4uDB6mUWd2"
      },
      "source": [
        "3. Obtenga la representaciÃ³n vectorial del vocabulario con el *word embedding* GloVe entrenado en [Wikipedia 2014 + GigaWord 5](https://nlp.stanford.edu/projects/glove/). Para ello:\n",
        "- Instancie el objeto `glove` como una instancia de la clase `torchtext.vocab.GloVe` con los parÃ¡metros`name=\"6B\", dim=300`.\n",
        "- Ejecute el mÃ©todo `build_vocab` del objeto `documento_fd` con `max_size=20000` y los demÃ¡s parÃ¡metros que correspondan   \n",
        "  Compruebe posteiormente que al llamar a `documento_fd.vocab.vectors.shape` obtiene las dimensiones `(20002,300)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5l65cImC6in6",
        "colab": {}
      },
      "source": [
        "glove= GloVe(name='6B', dim=300)\n",
        "\n",
        "documento_fd.build_vocab(train_td,max_size=20000,vectors=glove)\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xLkdtNzPmuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d1b5afb-1d68-41f1-8b44-ef57193c97d6"
      },
      "source": [
        "documento_fd.vocab.vectors.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20002, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iQ875UiZYrY4"
      },
      "source": [
        "#### LSTM \n",
        "Finalmete se implementa una LSTM bidireccional. La estructura de la red LSTM ya fue revisada en el material del curso, sin embargo, no se estudiÃ³ su variante bidireccional. Esta denominaciÃ³n implica que la secuencia de tokens presente en cada texto es procesada desde el primer token hasta el Ãºltimo en una LSTM y desde el ÃºÄºtimo hasta el primero en otra LSTM, tal como lo ilustra la siguiente imagen.\n",
        "\n",
        "<center> <img src=\"http://colah.github.io/posts/2015-09-NN-Types-FP/img/RNN-bidirectional.png\" align=\"middle\"> </center>\n",
        "<center> Fuente: <a href=\"http://colah.github.io/posts/2015-09-NN-Types-FP/\"> Colah's Blog </a></center>\n",
        "\n",
        "Por consistencia con la imagen, supongamos que la LSTM bidireccional recibe un documento compuesto por la secuencia de tokens $x_0, \\ldots, x_u$, de largo $i+1$. Sean $\\text{LSTM}$ la RNN que recibe los inputs desde $0$ hasta $i$ y $\\text{LSTM}'$ la RNN que los recibe desde $i$ hasta $0$. A cada input de la secuencia, $x_j$, corresponde un *output*, $y_j$ que consiste en la concatenaciÃ³n $\\left(A(S_j, x_j),A'(S'_{i-j}, x_j)\\right)$. Lo que debe ser considerado como la salida final de la LSTM bidireccional es la primera mitad de $y_i$ y la segunda mitad de $y_0$ pues corresponden a $A(S_i, x_i)$ y $A'(S'_i, x_0)$ respectivamente. Observe que este es output se asocia a la secuencia completa.\n",
        "\n",
        "La LSTM bi-direccional que se implementa estÃ¡ diseÃ±ada para usar un *word embedding* fijo, como el que fue calculado en la secciÃ³n anterior.\n",
        "\n",
        "La estructura de la red es la siguiente:\n",
        "- *Word embedding* pre-entrenado (no deben calcularse gradientes en esta secciÃ³n de la red), implementado con la clase `torch.nn.Embedding`.\n",
        "- LSTM bidireccional, tomando como salida la concatenaciÃ³n reciÃ©n explicada e implementada con la clase `torch.nn.LSTM` con los parÃ¡metros `batch_first=True` y `bidirectional=True`. \n",
        "- Dropout con probabilidad .5\n",
        "- Capa totalmente conectada con salida de tamaÃ±o 1 y funciÃ³n de activaciÃ³n sigmoide.\n",
        "\n",
        "Dado que `~.BucketIterator` entrega un tensor con *paddings* de cero, es necesario transformar el input de `~.LSTM`, de tal forma que esta no procese los ceros del tensor de entrada. Por esta razÃ³n al pasar del output de `~.Embedding`, al input de `~.LSTM`, es necesario emplear la funciÃ³n `torch.nn.utils.rnn.pack_padded_sequence` que permite transformar una secuencia con *paddings* de 0, en una secuencia que los oculta. Dicha funciÃ³n es capaz de transformar un input de la forma:\n",
        "```\n",
        "seq = torch.tensor([[4,5,6], [1,2,0], [3,0,0]])\n",
        "lens = [3, 2, 1]\n",
        "packed = pack_padded_sequence(seq, lens, batch_first=True, enforce_sorted=True)\n",
        "```\n",
        "donde el objeto `packed` tendrÃ¡ la forma:\n",
        "```\n",
        "PackedSequence(data=tensor([4, 1, 3, 5, 2, 6]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
        "```\n",
        "y estarÃ¡ listo para ser procesado como entrada de `~.LSTM`.\n",
        "\n",
        "Sin embargo, el empleo de aquella funciÃ³n, obliga a usar su funciÃ³n inversa, `torch.nn.utils.rnn.pad_packed_sequence`, sobre la salida de `~.LSTM` y asÃ­ que pasar de un objeto `PackedSequence` a su formato tensorial con *padding* de 0. En consecuencia al emplear:\n",
        "```\n",
        "lstm = nn.LSTM(...)\n",
        "packed_output, _ = lstm(packed)\n",
        "seq_unpacked, lens_unpacked = pad_packed_sequence(packed, batch_first=True)\n",
        "``` \n",
        "Esto permitirÃ¡ encontrar el output de la LSTM bidireccional en el tensor `seq_unpacked` de tamaÃ±o $B \\times T \\times C$, donde $B$ representa el tamaÃ±o del *batch*, $T$ el largo de la secuencia mÃ¡s larga del *batch* y $C$ el tamaÃ±o de la dimension del espacio de carÃ¡cteristicas de la salida de `~.LSTM`. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e0r7-VImYqgc"
      },
      "source": [
        "##### Pregunta 5\n",
        "\n",
        "1. Defina la clase `Glove6B300BiLSTM` heredando de `torch.nn.Module` y definiendo los mÃ©todos:\n",
        "- `__init__`: recibe como parametros `hidden_size`, que regula el parÃ¡metro homÃ³nimo de `torch.nn.LSTM`; y `text_field` que apunta al `torchtext.data.Field` que ya contiene la representaciÃ³n vectorial densa del *vocabulario* que es utilizado en la capa del *word embedding*.  \n",
        "- `forward`: recibe como argumentos `text` y `text_len` que corresponden a los objetos que entrega `BucketIterator`.  \n",
        "Haga uso de las funciones `~.pack_padded_sequence` con parÃ¡metros `batch_first=True, enforce_sorted=True` y `~.pad_packed_sequence`, con parÃ¡metro `batch_first=True`. Sea ciudadoso en la selecciÃ³n de los segmentos del tensor de salida de `~.pad_packed_sequence` que deben ser considerados para las capas posteriores.   \n",
        "\n",
        "*Hint*: note que para construir el output de la $\\text{LSTM}$ bidireccional, deberÃ¡ seleccionar segmentos de un vector de salida y concatenarlos de manera conveniente. Para ello le serÃ¡ de ayuda la variable `text_len`.\n",
        "\n",
        "  \n",
        "Instancie `modelo` como objeto de la clase `Glove6B300BiLSTM` con `hidden_size=128` y `text_field=documento_fd`. Recuerde instanciarlo en el espacio de memoria adecuado mediante el mÃ©todo `to(device)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iXgixLg3f_Pc",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dMfKHOKtgMdJ"
      },
      "source": [
        "2. Implemente el ciclo de entrenamiento de la red `Glove6B300BiLSTM`. Para ello use:\n",
        "- EntropÃ­a cruzada binaria como funcion de costo - `torch.nn.BCELoss()`\n",
        "- Adam cÃ³mo algoritmo de optimizaciÃ³n, con `lr=2e-4`\n",
        "- 10 epocas de entrenamiento\n",
        "- Los `BucketIterator` definidos en la pregunta anterior para recorrer los conjuntos de entrenamiento y validaciÃ³n.\n",
        "- Guarde en una lista el historico de valores de la funciÃ³n de costo en el conjunto de entrenamiento y de validaciÃ³n\n",
        "- Al final de cada Ã©poca guarde el modelo mediante `guardar_modelo` en la ruta `modelos/Glove6B300BiLSTM.h5`, si es que la funciÃ³n de costo sobre el conjunto de validaciÃ³n es menor que la menor funciÃ³n de costo sobre el conjunto de validaciÃ³n observada en Ã©pocas anteriores. \n",
        "\n",
        "Al finalizar el entrenamiento, muestre en pantalla un grÃ¡fico con el historico de la funciÃ³n de costo en el conjunto de entrenamiento y en el de validaciÃ³n y guardelo en `resultados/Glove6B300BiLSTM/costo_historico.pdf`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AvYtjhfcgM69",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j7m7lmgRqeUj"
      },
      "source": [
        "3. Obtenga la predicciÃ³n de `modelo` sobre el conjunto de prueba y reporte el desempeÃ±o del clasificador mediante `evalua_sklearn` con la predicciÃ³n de `modelo` sobre el conjunto de *prueba*, usando `nombre_clasificador='Glove6B300BiLSTM'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fNp0XVDeqdq2",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}